{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando o tensorflow e o keras\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "# Importando o matplotlib para plotar as imagens\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar dataset disponivel dentro do keras\n",
    "# O dataset contem 70 mil imagens, portanto 60 mil é de treino e 10 mil é de teste\n",
    "dataset = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "# Ao carregar o DataSet, o retorno é duas tuplas, onde a primeira contem imagens e identificações de treino (x,y)\n",
    "# e o segundo contem imagens e identificações de teste (x,y)\n",
    "((imagens_treino, identificacoes_treino),(imagens_teste, identificacoes_teste)) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos analisar a dimensão do nosso array com o shape\n",
    "# Formato do array\n",
    "# Temos 60000 registro de array de 28 linhas 28 coluna\n",
    "imagens_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temos 10000 registro de array de 28 linhas 28 coluna\n",
    "# Imagens de treino\n",
    "imagens_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels de treino: ', len(identificacoes_treino),'Labels de Teste: ', len(identificacoes_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A identificação minima \n",
    "identificacoes_treino.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A identificação maxima\n",
    "identificacoes_treino.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_de_classificadores = 10\n",
    "# Mapear os classificadores de 0 a 9 por nomes\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "nomes_de_classificadores = ['Camiseta', 'Calça', 'Pullover', 'Vestido', \n",
    "                            'Casaco', 'Sandalia', 'Camisa', 'Tenis', 'Bolsa', 'Bota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fd4e00f3198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "for imagem in range(10):\n",
    "#     Configurando o sub plot para exibir 2 linha e 5 colunas de imagens\n",
    "    plt.subplot(2,5,imagem+1)\n",
    "    # Platando a primeira imagem de index[0]\n",
    "    plt.imshow(imagens_treino[imagem])\n",
    "    # Adicionando um titulo a img\n",
    "    plt.title(nomes_de_classificadores[identificacoes_treino[imagem]])\n",
    "'''\n",
    "\n",
    "# Podemos plotar uma barra de cores para identificar a gradação das cores\n",
    "plt.imshow(imagens_treino[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link para scipy img, lib para manipular imagens\n",
    "http://scipy-lectures.org/advanced/image_processing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Camadas do moadelo\n",
    "# modelo sequencial\n",
    "#     entrada\n",
    "#     processamento\n",
    "#     saida\n",
    "\n",
    "# NORMALIZAÇÃO DAS IMAGENS\n",
    "# Dimunindo o processamento de pixels de 255 para 0 a 1. A rede não precisa processar 255 pixels e sim de 0 a 1 \n",
    "# com suas diferença, ou seja, 0.10, 0.30,1, etc\n",
    "imagens_treino = imagens_treino / float(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um modelo sequencial, onde temos a entrada, processamento e saida dos dados\n",
    "modelo = keras.Sequential([\n",
    "#   Camanda de entrada\n",
    "#   Na priemira camada, vamos pegar as imagens de 28x28 e achatar para um unico array de 784(28x28) posições\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "#   CAMADAS OCULTAS, porque não é possivel saber o que esta acontencendo para realizar o agrupamento \n",
    "#   dos neuronios.\n",
    "#   Camada de processamento\n",
    "#   Criando 256 camandas \"bolinhas\" que vão ser densar e comunicar com a camada de Flatten, ou seja\n",
    "#   a camada com a imagem em um unico array de pixels\n",
    "#   Alem de termos 256(Recomendado multiplos de 2. Temos que testar o que é melhor para o que queremos)\n",
    "#   pequenos tensores, temos dizer quando eles vão ser ativados, \n",
    "#   que é o relu, uma ativação de redes mais utilizada na comunidade\n",
    "#   reLU = Unidade linear retificada\n",
    "#   AS CAMADAS OCULTAS TEM QUE SER TESTADA PARA CHEGAR NA MENOR PERDA(LOSS)\n",
    "#   A EXECUÇÃO DA COMPILAÇÃO ARMAZENA ALGUMAS VARIAVEIS DE ESTADO DO MODELO E O JUPYTER TAMBEM ARMAZEMA\n",
    "#   O QUE FAZ COM QUE O MODELO GERE SEMPRE O MESMO RESULTADO, PARA ISSO TEMOS QUE RESTARTAR O NOTEBOOK\n",
    "    keras.layers.Dense(256, activation=tensorflow.nn.relu),\n",
    "#     keras.layers.Dense(128, activation=tensorflow.nn.relu),\n",
    "#     keras.layers.Dense(64, activation=tensorflow.nn.relu),\n",
    "#   NORMALIZANDO MODELO\n",
    "#   O dropout mantem 20% das camadas adormecidas para que a rede não fique muito \"viciada\" com muitas informações\n",
    "    keras.layers.Dropout(0.2),\n",
    "#   Camada de Saida\n",
    "#   O numero da camada de saída é a quantidade de classificações que o modelo vai conter\n",
    "#   O softmax é uma função que extrai da imagem probabilidades em % de todas outras imagens \n",
    "    keras.layers.Dense(10, activation=tensorflow.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando é realizado o treinamento, os dados de aprendizado passa por um \"ciclo\" de ida e volta no dentro do \n",
    "# modelo, ou seja, entra em \n",
    "# flatten -> Dense(neuronios) -> Dropout -> Dense(Softmax) -> flatten(2x) -> Dense(2x)  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tabela que resume o nosso modelo\n",
    "# Olhando a tabela abaixo em Shape, podemos analisar que é os mesmo dados que configuramos o modelo, 28*28 = 784\n",
    "# Param => O param é \n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compinando o modelo antes de treinar\n",
    "modelo.compile(\n",
    "    # Otimizador de treinamento da rede\n",
    "    optimizer='adam',\n",
    "    # Perda de informação da rede. Se a rede classificar um item errado, ela vai ter uma perda de informação\n",
    "    # para calcular a perda, vamos utilizar a \"entropia categorica cruzada esparsa\" \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # Adicionando métricas para identificar o quanto o modelo esta acertando\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando um modelo\n",
    "# epoch é a quantidade de vezes que o modelo vai ser treinado\n",
    "# validation_split é a quantidade de registro que vamos usar para validar o desempenho, 0.2 = 20%\n",
    "historico = modelo.fit(imagens_treino, identificacoes_treino, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando e carregando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando e carregando o modelo\n",
    "modelo.save('modelo_epochs5_nos4.h5')\n",
    "modelo.save()\n",
    "\n",
    "modelo_salvo = load_model('modelo_epochs5_nos4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando gráfico de acuracia por epoch do treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvamos o historico de treinamento do modelo para plotar um grafico com os resultados\n",
    "# PLOTANDO GRAFICO DE DESEMPENHO DO MODELO\n",
    "# Plotando dois array de dados\n",
    "plt.plot(historico.history['acc'])\n",
    "plt.plot(historico.history['val_acc'])\n",
    "# Configurando titulo do grafico\n",
    "plt.title('Acuracia por epocas')\n",
    "# label do eixo x\n",
    "plt.xlabel('epochs')\n",
    "# label do eixo y\n",
    "plt.ylabel('accuracy')\n",
    "# Adicionando legendas\n",
    "plt.legend(['treino', 'validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando gráfico de perda por epoch do treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTANDO GRAFICO DE PERDA DO MODELO\n",
    "# Plotando dois array de dados\n",
    "plt.plot(historico.history['loss'])\n",
    "plt.plot(historico.history['val_loss'])\n",
    "# Configurando titulo do grafico\n",
    "plt.title('Perda por epocas')\n",
    "# label do eixo x\n",
    "plt.xlabel('epochs')\n",
    "# label do eixo y\n",
    "plt.ylabel('loss')\n",
    "# Adicionando legendas\n",
    "plt.legend(['treino', 'validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de comunicação das camandas feita pela camada Dense\n",
    "<img src=\"./dense.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo do funcionamento da reLU\n",
    "<img src=\"./relu.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o modelo e o modelo salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando predições no modelo\n",
    "testes = modelo.predict(imagens_teste)\n",
    "\n",
    "print('Resultado teste:', np.argmax(testes[1]))\n",
    "print('numero da imagem de teste:', identificacoes_teste[1])\n",
    "\n",
    "testes = modelo_salvo.predict(imagens_teste)\n",
    "\n",
    "print('Resultado teste modelo salvo:', np.argmax(testes[1]))\n",
    "print('numero da imagem de teste modelo salvo:', identificacoes_teste[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalidando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o desempenho do modelo\n",
    "# O evaluate retornaum array com 2 posição onde a primeira é a perda do array e a segunda a acuracia\n",
    "perda_teste, acuracia_teste = modelo.evaluate(imagens_teste, identificacoes_teste)\n",
    "print('Perda do teste:', perda_teste)\n",
    "print('Acuracia do teste:', acuracia_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export_keras_to_tf(output_model, num_output):\n",
    "#     print('Loading Keras model: ', 'modelo_epochs5_nos4.h5')\n",
    "\n",
    "#     keras_model = load_model('modelo_epochs5_nos4.h5')\n",
    "\n",
    "#     print(keras_model.summary())\n",
    "\n",
    "#     predictions = [None] * num_output\n",
    "#     predrediction_node_names = [None] * num_output\n",
    "\n",
    "#     for i in range(num_output):\n",
    "#         predrediction_node_names[i] = 'output_node' + str(i)\n",
    "#         predictions[i] = tf.identity(keras_model.outputs[i], \n",
    "#         name=predrediction_node_names[i])\n",
    "\n",
    "#     sess = K.get_session()\n",
    "\n",
    "#     constant_graph = graph_util.convert_variables_to_constants(sess, \n",
    "#     sess.graph.as_graph_def(), predrediction_node_names)\n",
    "#     infer_graph = graph_util.remove_training_nodes(constant_graph) \n",
    "\n",
    "#     graph_io.write_graph(infer_graph, '.', output_model, as_text=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
